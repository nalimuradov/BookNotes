sentiment analysis:
 - the extaction of sentiment
 - the positive/negative orientation that writer expresses
 - eg. review of a movie
 - simplest sentiment analysis:
	- binary classification: eg. greatly/awesome vs trash/awful
	- spam detection is another simple example (key spam words)

classification:
 - extremely useful to classify data into buckets
 - generative classifiers (naive bayes):
	- return class most likely to have generated the observation
 - discriminative classifiers (logistic regression):
 	- learn what features from input are most useful to distinguish between possible classes

naive bayes:
 - we can calculate the class of a document by:
	- c = max(P(d|c) * P(c))
		- removed denom because it's the same for each class
	- to find the class, we need the prior probability of the class P(c) and the likelihood of the doc P(d|c)

 - we can also represent document d as a set of features f1 to fn
	- c = max(P(f1, f2, .. | c) * P(c))

 - to simplify, we ignore the word positions and only care about count
	- we also assume that probabilities of features are independent of each other
	- this is why it's called NAIVE bayes

 - naive bayes calculations are also done in log space (like language modeling) to avoid underflow
 - it is a linear classifier:
	- classifiers that use a linear combination of the inputs to make a classification decision

training the naive bayes classifier:
 - we can assume P(c) will be N_c/N_doc
 	- N_c is the number of docs in the training data with class 'c'
	- N_doc is the total number of documents in the training data
	
 - to find P(f_i|c)
 	- assume a feature is just the existence of the word in the bag -> P(w_i|c)

 - eg. P("fantastic"|positive) = count("fantastic", positive) / sum of count(w, positive)
 	- if "fantastic" doesn't appear in any positive reviews, will be zero!
	- as such, we implement Laplace (add-1) smoothing
		- add 1 to numerator and add |V| to denominator
		
 - unknown words:
 	- if words appear in test set that didn't appear in train set, ignore them
	- do not include any probability for them at all

 - stop words:
  	- some systems may choose to ignore stop words (eg. the, a)
	- can be done by removing 10-100 most common words in bag
	- optional and not necessary
	
 - example:
 	- Training Data:
		- "just plain boring" -> negative
		- "entirely predictable and lacks energy" -> negative
		- "no surprises and very few laughs" -> negative
		- "very powerful" -> positive
		- "the most fun film of the summer" -> positive
	- Testing Data:
		- "predictable with no fun" -> ?
		- first remove all words that do not appear in training set (ie. "with")
		- find class probabilities: P(negative) = 3/5, P(positive) = 2/5
		- find probability of each word with respect to each class
			- multiply and pick which is more likely
			- in this case, it predicts the sentence as NEGATIVE

binary naive bayes:
 - clip the word counts in each document at 1 (remove all duplicates)
 - for sentiment analysis, the existence of a word matters much more than frequency
 - if a word appears in multiple docs, it will still have a count greater than 1
 
negation:
 - "amazing" and "not amazing" have opposite meanings
 - to deal with negation, append NOT_ to every word after a logical negation until the next punctuation mark
 	- eg. didnt like movie, but 
		- didnt NOT_like NOT_movie, but
		
sentiment lexicons:
 - pretrained lists of words that are annotated with positive/negative sentiment
 - eg. POSITIVE: admirable, beautiful, ...
 - eg. NEGATIVE: awful, cheap, ...
 - some lexicons are LIWC, MPQA, ...
 - can be used as an additional feature in a naive bayes classifier
 	- if a word in the positive lexicon of MPQA occurs, add it
	
language detection:
 - can use byte n-grams to detect language ID by finding characters that are specific to one language
 - eg. 'zw' or 'ie z' or 'thei'
 
sentence probability:
 - P(I love this|+) = P(I|+) * P(love|+) * P(this|+)
 
system evaluation:
 - accuracy is misleading, as a classifier can have high accuracy on imbalance datasets by always predicting one class
 - f-scores are better, f1-score is common
 	- f1-score is f-score with beta = 1
 - precision = tp/tp+fp
 - recall = tp/tp+fn
 - f-measure is the harmonic mean of precision and recall
 	- harmonic mean is the reciprocal of the arithmetic mean of reciprocals
	- harmonic mean is used as it is closer to the lower of two values (thus having one lower than other is more impactful)

multiple classes: 
 - two types of multi-class classification tasks:
	- multi-label classification: each item can have more than one label
		- given a test doc d, pass through each classifier to determine which ones it fits in
	- multinomial classification: classes are mutually exclusive
		- run all classifiers and choose label whose classifier has highest score

cross-validation:
 - all data used to train and test
 - split into k sections, and test on one of those sections based on a trained model from other sections
 - what i did with signature detection